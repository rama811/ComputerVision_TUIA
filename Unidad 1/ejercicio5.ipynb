{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ubAjNIwjMboT",
        "49vnm86u_1MO",
        "2-AI6IWs_sit",
        "ycPuHpzCA9IY",
        "LAmZ1gHxL-ir"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalaciones y librerías necesarias"
      ],
      "metadata": {
        "id": "ubAjNIwjMboT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg\n",
        "!pip install -q mediapy"
      ],
      "metadata": {
        "id": "4iZKMWIxc1Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import subprocess\n",
        "import mediapy as media"
      ],
      "metadata": {
        "id": "cLHJ4BIEaIaQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ggUbF3UJburK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Motion detection"
      ],
      "metadata": {
        "id": "49vnm86u_1MO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tMP5biADZdZs"
      },
      "outputs": [],
      "source": [
        "def process_frame_difference(new_image, prev_image, movement=False, **kwargs):\n",
        "    # Convertir las imágenes a escala de grises\n",
        "    new_gray = cv2.cvtColor(new_image, cv2.COLOR_RGB2GRAY)\n",
        "    prev_gray = cv2.cvtColor(prev_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Calcular la diferencia absoluta entre los fotogramas actual y anterior\n",
        "    frame_diff = cv2.absdiff(new_gray, prev_gray)\n",
        "\n",
        "    # Umbralizar la imagen para resaltar las diferencias\n",
        "    _, thresh = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    #cv2_imshow(thresh)\n",
        "\n",
        "    # Encontrar componentes conectadas\n",
        "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(thresh)\n",
        "\n",
        "    # Filtrar componentes por área\n",
        "    min_area = 1000\n",
        "    filtered_mask = np.zeros_like(prev_image)\n",
        "    for i in range(1, num_labels):\n",
        "        x, y, w, h, area = stats[i]\n",
        "\n",
        "        # Calcular el aspect ratio del rectángulo\n",
        "        aspect_ratio = w / float(h)\n",
        "\n",
        "        # Filtrar por área y aspect ratio\n",
        "        if area > min_area:\n",
        "            # Acumular la región en la máscara\n",
        "            filtered_mask[labels == i] = 255\n",
        "            # Establecer movimiento en la imagen\n",
        "            movement = True\n",
        "\n",
        "    #cv2_imshow(filtered_mask)\n",
        "\n",
        "    return movement"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del video\n",
        "video_path = '/content/drive/My Drive/computer_vision/video_emi.mp4'\n",
        "video_path_reduced = '/content/drive/My Drive/computer_vision/video_emi_reduced.mp4'\n",
        "\n",
        "# Comando para reducir la resolución del video original\n",
        "ffmpeg_command = f'ffmpeg -i \"{video_path}\" -vf \"scale=-1:180\" \"{video_path_reduced}\"'\n",
        "\n",
        "# Ejecutar el comando de ffmpeg para reducir la resolución\n",
        "subprocess.call(ffmpeg_command, shell=True)\n",
        "\n",
        "# Cargar el video\n",
        "cap = cv2.VideoCapture(video_path_reduced)\n",
        "\n",
        "# Leer el primer fotograma\n",
        "ret, prev_frame = cap.read()\n",
        "\n",
        "# Bucle para procesar cada fotograma\n",
        "while cap.isOpened():\n",
        "    # Leer el fotograma actual\n",
        "    ret, new_frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # Salir del bucle si no hay más fotogramas\n",
        "\n",
        "    # Procesar el par de fotogramas\n",
        "    processed_frame = process_frame_difference(new_frame, prev_frame)\n",
        "    if processed_frame == True:\n",
        "        print(\"Movimiento detectado\")\n",
        "\n",
        "    # Salir del bucle si se presiona la tecla 'q'\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    # Actualizar el fotograma anterior\n",
        "    prev_frame = new_frame\n",
        "\n",
        "\n",
        "# Liberar recursos y cerrar ventanas\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "OzQyghGUapHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flujo óptico denso"
      ],
      "metadata": {
        "id": "2-AI6IWs_sit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para procesar un video:\n",
        "def video_processor(filename_in, filename_out, process_func, max_time=10, **kwargs):\n",
        "    # Abrir el video de entrada para lectura\n",
        "    with media.VideoReader(filename_in) as r:\n",
        "        # Crear un archivo de video de salida\n",
        "        with media.VideoWriter(filename_out, shape=r.shape, fps=r.fps, bps=r.bps) as w:\n",
        "            count = 0  # Inicializar contador de fotogramas\n",
        "            prev_image = None  # Inicializar la imagen previa\n",
        "\n",
        "            # Iterar sobre cada imagen (fotograma) del video\n",
        "            for image in r:\n",
        "                new_image = media.to_uint8(image)  # Convertir la imagen a formato flotante\n",
        "\n",
        "                # Comprobar si es la primera imagen\n",
        "                if prev_image is None:\n",
        "                    prev_image = new_image.copy()\n",
        "\n",
        "                # Procesar la imagen utilizando la función dada\n",
        "                processed_image = process_func(new_image, prev_image, **kwargs)\n",
        "\n",
        "                # Añadir la imagen procesada al video de salida\n",
        "                w.add_image(processed_image)\n",
        "\n",
        "                # Actualizar la imagen previa\n",
        "                prev_image = new_image.copy()\n",
        "\n",
        "                # Incrementar el contador de fotogramas\n",
        "                count += 1\n",
        "\n",
        "                # Detener el proceso si se alcanza el tiempo máximo\n",
        "                if count >= max_time * r.fps:\n",
        "                    break"
      ],
      "metadata": {
        "id": "HAHwH4hnFVOY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para procesar el flujo óptico denso\n",
        "def process_dense_optical_flow(new_image, prev_image):\n",
        "    # Convierte la nueva imagen a escala de grises\n",
        "    gray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    if not hasattr(process_dense_optical_flow, \"init_done\"):\n",
        "        process_dense_optical_flow.prev_gray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
        "        process_dense_optical_flow.mask = np.zeros_like(new_image)\n",
        "        process_dense_optical_flow.mask[..., 1] = 255\n",
        "        process_dense_optical_flow.init_done = True\n",
        "\n",
        "    if process_dense_optical_flow.init_done:\n",
        "        prev_gray = process_dense_optical_flow.prev_gray\n",
        "        mask = process_dense_optical_flow.mask\n",
        "\n",
        "    # Calcula el flujo óptico\n",
        "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    # Computa magnitud y ángulo de los vectores 2D\n",
        "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    # Establece el tono de la imagen según la dirección del flujo óptico\n",
        "    mask[..., 0] = angle * 180 / np.pi / 2\n",
        "    # Establece el valor de la imagen según la magnitud del flujo óptico\n",
        "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    # Convierte de HSV a RGB\n",
        "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
        "    # Actualiza la imagen previa a gris\n",
        "    process_dense_optical_flow.prev_grayprev_gray = gray.copy()\n",
        "    return rgb"
      ],
      "metadata": {
        "id": "Z3sx5-ws_vDt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del video\n",
        "video_path = '/content/drive/My Drive/computer_vision/video_emi.mp4'\n",
        "video_path_reduced = '/content/drive/My Drive/computer_vision/video_emi_reduced.mp4'\n",
        "\n",
        "# Comando para reducir la resolución del video original\n",
        "ffmpeg_command = f'ffmpeg -i \"{video_path}\" -vf \"scale=-1:180\" \"{video_path_reduced}\"'\n",
        "\n",
        "# Ejecutar el comando de ffmpeg para reducir la resolución\n",
        "subprocess.call(ffmpeg_command, shell=True)\n",
        "\n",
        "# Nombres de los archivos de video de entrada y salida\n",
        "filename_in = video_path_reduced\n",
        "filename_out = '/content/drive/My Drive/computer_vision/video_emi_dense.mp4'\n",
        "\n",
        "# Llamar a la función para procesar el video\n",
        "video_processor(filename_in, filename_out, process_dense_optical_flow,\n",
        "                max_time=20)\n",
        "\n",
        "# Mostrar el video resultante\n",
        "media.show_video(media.read_video(filename_out), fps=30)"
      ],
      "metadata": {
        "id": "T5C2MB1gFeWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flujo óptico disperso"
      ],
      "metadata": {
        "id": "ycPuHpzCA9IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_sparse_optical_flow(new_image, prev_image):\n",
        "    # Preparamos las imagenes de trabajo\n",
        "    new_gray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
        "    prev_gray_image = cv2.cvtColor(prev_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Verificar si ya se han detectado las características de Shi-Tomasi\n",
        "    if not hasattr(process_sparse_optical_flow, \"shi_tomasi_done\"):\n",
        "        # Definir parámetros para la detección de esquinas de Shi-Tomasi\n",
        "        feature_params = dict(maxCorners=300, qualityLevel=0.2, minDistance=2, blockSize=7)\n",
        "        # Detectar puntos característicos en la imagen\n",
        "        process_sparse_optical_flow.prev_points = cv2.goodFeaturesToTrack(new_gray, mask=None, **feature_params)\n",
        "        # Crear una máscara para dibujar el flujo óptico\n",
        "        process_sparse_optical_flow.mask = np.zeros_like(new_image)\n",
        "        # Marcar que se ha completado la detección de Shi-Tomasi\n",
        "        process_sparse_optical_flow.shi_tomasi_done = True\n",
        "\n",
        "    # Continuar si se ha completado la detección de Shi-Tomasi\n",
        "    if process_sparse_optical_flow.shi_tomasi_done:\n",
        "        prev_points = process_sparse_optical_flow.prev_points\n",
        "        mask = process_sparse_optical_flow.mask\n",
        "\n",
        "    # Parámetros para el flujo óptico de Lucas-Kanade\n",
        "    lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
        "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "    # Calcular el flujo óptico de Lucas-Kanade\n",
        "    new_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray_image, new_gray, prev_points, None, **lk_params)\n",
        "    # Filtrar puntos buenos\n",
        "    good_old = prev_points[status == 1]\n",
        "    good_new = new_points[status == 1]\n",
        "    color = (0, 255, 0)  # Color para el dibujo\n",
        "    # Dibujar el movimiento (flujo óptico)\n",
        "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "        a, b = new.astype(int).ravel()\n",
        "        c, d = old.astype(int).ravel()\n",
        "        mask = cv2.line(mask, (a, b), (c, d), color, 2)\n",
        "        new_image = cv2.circle(new_image, (a, b), 3, color, -1)\n",
        "\n",
        "    # Combinar la imagen actual con las líneas de flujo óptico dibujadas\n",
        "    output = cv2.add(new_image, mask)\n",
        "    # Actualizar puntos para el siguiente cuadro\n",
        "    process_sparse_optical_flow.prev_points = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "MiLzn6L0BBfX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del video\n",
        "video_path = '/content/drive/My Drive/computer_vision/video_emi.mp4'\n",
        "video_path_reduced = '/content/drive/My Drive/computer_vision/video_emi_reduced.mp4'\n",
        "\n",
        "# Comando para reducir la resolución del video original\n",
        "ffmpeg_command = f'ffmpeg -i \"{video_path}\" -vf \"scale=-1:180\" \"{video_path_reduced}\"'\n",
        "\n",
        "# Ejecutar el comando de ffmpeg para reducir la resolución\n",
        "subprocess.call(ffmpeg_command, shell=True)\n",
        "\n",
        "# Nombres de los archivos de video de entrada y salida\n",
        "filename_in = video_path_reduced\n",
        "filename_out = '/content/drive/My Drive/computer_vision/video_emi_sparse.mp4'\n",
        "\n",
        "# Llamar a la función para procesar el video\n",
        "video_processor(filename_in, filename_out, process_sparse_optical_flow,\n",
        "                max_time=20)\n",
        "\n",
        "# Mostrar el video resultante\n",
        "media.show_video(media.read_video(filename_out), fps=30)"
      ],
      "metadata": {
        "id": "5hJuk6GeI2gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflexión de resultados"
      ],
      "metadata": {
        "id": "LAmZ1gHxL-ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En cuanto al primer procesamiento de detección de movimiento, se encontraron resultados favorables y que suponen de utilidad para aplicaciones de seguridad. Esto se logró realizando una umbralización de la imagen, para luego encontrar los componentes conectados y filtrarlos por area mínima (adicionalmente se podría establecer un filtro de relación de aspecto).\n",
        "\n",
        "Luego, en ambos procesamientos de flujo óptico, se realizan utilizando el código visto en clases. Los resultados obtenidos no son del todo aceptables ya que la detección de movimiento se genera desde el inico del video (por cambios normales en cualquier video), afectando al objetivo de las técnicas de hacer seguimiento a objetos.\n",
        "Una solución a esto podría ser preprocesar las imágenes con técnicas de morfología."
      ],
      "metadata": {
        "id": "4gcpRh0GMDW2"
      }
    }
  ]
}